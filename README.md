# neat-rnn
This is a precise to-read list for recurrent neural network (RNN). 

One line per citation. Omit the long author lists; start with year, followed by title, jounral, and links. 

Maintainer: [Johnny Ho] (https://github.com/johnny5550822)

# Contributions
Please submit pull requests! For any questions, contact me (johnny5550822@g.ucla.edu)

# Additional resources
You can also find good staffs in [awesome-rnn] (https://github.com/kjw0612/awesome-rnn). 

## Review
+ 2015 Deep Learning, Nature [[paper](http://www.nature.com/nature/journal/v521/n7553/full/nature14539.html)]

## Translation
+ 2014 Sequence to Sequence Learning with Neural Networks, NIPS [[paper](http://papers.nips.cc/paper/5346-sequence-to-sequence-learning-with-neural-networks)]
+ 2014 On the Properties of Neural Machine Translation: Encoderâ€“Decoder Approaches, arXiv [[paper](http://arxiv.org/abs/1409.1259)]
+ 2014 Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation, arXiv [[paper](http://arxiv.org/abs/1406.1078)]
+ 2013 Recurrent Continuous Translation Models, EMNLP [[paper](http://nal.co/papers/KalchbrennerBlunsom_EMNLP13)]

## Visual Application
+ 2014 Recurrent Models of Visual Attention, 	arXiv [[paper](http://arxiv.org/abs/1406.6247)]

## Hand-writing
+ 2013 Generating Sequences With Recurrent Neural Networks, arXiv [[paper](http://arxiv.org/abs/1308.0850)]

## Text Generation
+ 2011 Generating Text with Recurrent Neural Networks, ICML [[paper](http://machinelearning.wustl.edu/mlpapers/paper_files/ICML2011Sutskever_524.pdf)]



## Gated Recurrent Neural Network
+ 2014 Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling, arXiv [[paper](http://arxiv.org/abs/1412.3555)]




arXiv [[paper]()]


